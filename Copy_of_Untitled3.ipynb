{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdXHb6yLKZMiEFOi0/l8MT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shtrausslearning/Deep-Learning-Projects/blob/main/Copy_of_Untitled3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from colorama import Fore, Style\n",
        "from datetime import timedelta\n",
        "import lightgbm as lgbm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# [j for i in lsts for j in i] combine lists in a list\n",
        "\n",
        "# Tokenise Corpus \n",
        "\n",
        "# import spacy\n",
        "# load small statistical model\n",
        "# nlp = spacy.load(\"en_core_web_sm\")\n",
        "# ldf[\"text_tkn\"] = ldf[\"text\"].apply(lambda x: nlp(x))"
      ],
      "metadata": {
        "id": "egtb5mBmDUv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TsnPngSMDSLT"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "\n",
        "class nlpi:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.corpus = {}\n",
        "        self.models = {}\n",
        "        self.vectoriser = {}\n",
        "        self.data = {}\n",
        "\n",
        "    def store(self,name,data):\n",
        "      self.data[name] = data\n",
        "        \n",
        "    # Convert lists of text to dataframe with label\n",
        "    @staticmethod\n",
        "    def lists_to_frame(lsts):\n",
        "\n",
        "        n_labels = len(lsts)\n",
        "\n",
        "        dict_txt = {'text':[],'class':[]}\n",
        "        for i,lst in enumerate(lsts):\n",
        "            dict_txt['text'] += lst\n",
        "            for j in lst:\n",
        "                dict_txt['class'].append(i)\n",
        "\n",
        "        return pd.DataFrame(dict_txt)\n",
        "        \n",
        "    # prepare corpus for a particular model\n",
        "        \n",
        "    def prepare(self,lst_docs,name):\n",
        "        df_corpus = self.lists_to_frame(lst_docs)\n",
        "        df_corpus = df_corpus.sample(frac=1)\n",
        "        self.corpus[name] = df_corpus\n",
        "        \n",
        "    # create a model based on corpus\n",
        "    \n",
        "    def train_store(self,name):\n",
        "        \n",
        "        vectorizer = CountVectorizer()\n",
        "        vectorizer.fit(self.corpus[name]['text'])\n",
        "        vectors = vectorizer.transform(self.corpus[name]['text'])\n",
        "        self.vectoriser[name] = vectorizer\n",
        "\n",
        "        X = vectors.todense()\n",
        "        y = self.corpus[name]['class'].values\n",
        "\n",
        "        # Create Classifier\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X,y)\n",
        "        self.models[name] = model\n",
        "\n",
        "        y_pred = model.predict(X)\n",
        "        score = model.score(X,y)\n",
        "        print(model,score)\n",
        "        \n",
        "        \n",
        "    # remove data associated with model\n",
        "        \n",
        "    def clear(self,name):\n",
        "        \n",
        "        if(name in self.corpus.keys()):\n",
        "            self.corpus.pop(name, None)\n",
        "        \n",
        "        if(name in self.models.keys()):\n",
        "            self.models.pop(name,None)\n",
        "        \n",
        "    # check available models\n",
        "        \n",
        "    def info(self):\n",
        "        print('Available Models:')\n",
        "        print(self.models.keys())\n",
        "    \n",
        "    # Inference on sentence to test model\n",
        "    \n",
        "    def test(self,name,sentence):\n",
        "        test_phrase = [sentence]\n",
        "        Xt_encode = self.vectoriser[name].transform(test_phrase)\n",
        "        y_pred = self.models[name].predict_proba(Xt_encode)\n",
        "        print(y_pred)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Dataset of possible commands\n",
        "plot_missing = ['plot missing data.',\n",
        "                 'find missing data.',\n",
        "                 'show missing data.',\n",
        "                 'show data that is missing',\n",
        "                 'find data that is missing',\n",
        "                 'missing data',\n",
        "                 'missingdata',\n",
        "                 'missdata',\n",
        "                 'data missing',\n",
        "                 'plot missing',\n",
        "                 'missing data, find it',\n",
        "                 'please find missing data',\n",
        "                 'please plot missing data',\n",
        "                 'please show missing data',\n",
        "                 'please show data which is missing',\n",
        "                 'plot seaborn missing data',\n",
        "                 'plot tabular missing data',\n",
        "                 'visualise missing data',\n",
        "                 'missing data bar plot',\n",
        "                 'missingdata']\n",
        "\n",
        "show_statistics = ['show describe',\n",
        "                  'show statistics',\n",
        "                  'show minimum',\n",
        "                  'show maximum',\n",
        "                  'show mean',\n",
        "                  'pandas describe',\n",
        "                  'pandas statistics',\n",
        "                  'statistics',\n",
        "                  'statistics of dataframe',\n",
        "                  'tabular statistics']\n",
        "\n",
        "show_fi = ['show feature importance',\n",
        "           'importance of features',\n",
        "           'model feature importance',\n",
        "           'please show importance of features',\n",
        "           'please show feature importance',\n",
        "           'create a feature importance plot',\n",
        "           'create feature importance plot']"
      ],
      "metadata": {
        "id": "6_eXeDSlDYz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "ldf = pd.DataFrame(np.random.random((3, 3)))"
      ],
      "metadata": {
        "id": "oDVSnMb_FpeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = nlpi()\n",
        "test.store(ldf,'data 1')\n",
        "\n",
        "test.prepare([plot_missing,show_statistics,show_fi],'eda')\n",
        "test.train_store('eda')\n",
        "test.test('eda','create a feature importance plot')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "k1dJ5eARDgAr",
        "outputId": "30f8788e-4248-4678-cc6b-9fd471394a76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2f2ca38f470c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mplot_missing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_statistics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshow_fi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'eda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'eda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-d6323ba864f7>\u001b[0m in \u001b[0;36mstore\u001b[0;34m(self, name, data)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Convert lists of text to dataframe with label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'DataFrame'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZNlIZ1AHDi3V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}